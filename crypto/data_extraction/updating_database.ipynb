{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2d9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import our dependencies\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from config import password\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "import datetime\n",
    "import requests\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22242e5",
   "metadata": {},
   "source": [
    "# First steps is to get a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b357b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a connection to the database and make the string into a variable\n",
    "\n",
    "rds_connection_string = f'postgres:{password}@localhost:5432/Cryptocurrencies'\n",
    "\n",
    "## Save this line for production connection to heroku database\n",
    "# app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL', '') or \n",
    "\n",
    "## Connect to local database\n",
    "\n",
    "connection_string = f'postgresql://{rds_connection_string}'\n",
    "\n",
    "## Create engine using the connection string to the database\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Reflect an existing database into a new model\n",
    "\n",
    "Base = automap_base()\n",
    "\n",
    "## reflect the tables\n",
    "\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679b5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find out the names of the tables available\n",
    "# Base.metadata.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846e2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a reference to the database tables we want to modify\n",
    "\n",
    "\n",
    "bitcoin_four_years_data = Base.classes.bitcoin_four_years_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d60778",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_community = Base.classes.btc_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.query(bitcoin_four_years_data.id, bitcoin_four_years_data.name, bitcoin_four_years_data.dt).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5560b",
   "metadata": {},
   "source": [
    "# You can also make queries and updates to tables in database using sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a83cd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sqlalchemy if you want to do nosql\n",
    "\n",
    "from sqlalchemy.orm import Session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bbdb4",
   "metadata": {},
   "source": [
    "## Example of querying using sqlalchemy session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can query using a session\n",
    "#session.query(test_entry_order.name, test_entry_order.time).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d77db2",
   "metadata": {},
   "source": [
    "## Example of adding records using SQLalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f95c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's add records using a session element\n",
    "\n",
    "# session.add(test_entry_order(name='erin', time=8.31))\n",
    "\n",
    "# # Commit and close the session for the changes to be uploaded to the databse\n",
    "\n",
    "# session.commit()\n",
    "# session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854802ea",
   "metadata": {},
   "source": [
    "## Example of queryng table using pandas and read_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of query using pandas\n",
    "#pd.read_sql_query(\"select * from test_entry_order\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9c2e0",
   "metadata": {},
   "source": [
    "## Example of adding records to a table using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This method works for adding records to postgres database even if it returns an error\n",
    "\n",
    "# pd.read_sql_query(\"insert into test_entry_order(name, time) values ('turt', 7.48)\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0dde0",
   "metadata": {},
   "source": [
    "## App that calculates how many missing dates there are between the table in question and today's date\n",
    "\n",
    "### It returns a list with the dates missing from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date in the format required to make the request\n",
    "\n",
    "def updated_dates_list(table_name):\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Get the most recent date from data base using a query\n",
    "    \n",
    "    most_recent_entry = pd.read_sql_query(f\"select dt from {table_name} order by dt desc limit 1\", con=engine)['dt'][0]\n",
    "\n",
    "\n",
    "    # Make list of dates between today and the most recent one, first get the number of days\n",
    "    \n",
    "    num_days = (today - most_recent_entry).days -1\n",
    "\n",
    "\n",
    "    # Now make a list conprehension to provide the lists\n",
    "    \n",
    "    missing_dates_descending_order = [today - datetime.timedelta(days=x) for x in range(num_days)]\n",
    "    missing_dates_ascending_order = [today - datetime.timedelta(days=num_days) + datetime.timedelta(days=x)for x in range(num_days+1)]\n",
    "    \n",
    "    ## Format the list to be apt for requests (Don't do this step here)\n",
    "    #missing_dates = [missing_dates[x] for x in range(len(missing_dates))]\n",
    "    \n",
    "    return missing_dates_ascending_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b462de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = updated_dates_list('bitcoin_four_years_data')\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec2841",
   "metadata": {},
   "source": [
    "## App that makes requests for the missing dates to the API end point of coingecko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make request for today's date\n",
    "\n",
    "\n",
    "def get_data_missing_dates(index_start = 0, last_index_wanted = len(missing_dates), token = 'bitcoin'):\n",
    "    \n",
    "    append_to = []\n",
    "    if len(missing_dates) == 0:\n",
    "        print(\"Database up to date\")\n",
    "\n",
    "    for x in range(index_start, 1):\n",
    "\n",
    "       \n",
    "        \n",
    "        date = {'date': missing_dates[x]}\n",
    "        print(\"now checking:\", missing_dates[x])\n",
    "        \n",
    "        url = f\"https://api.coingecko.com/api/v3/coins/{token}/history?date={missing_dates[x].strftime('%d-%m-20%y')}localization=False\"\n",
    "\n",
    "        try:\n",
    "            \n",
    "            ## If the request is succesful, combine the date dictionary with the response json\n",
    "    \n",
    "            response_json = requests.get(url).json()\n",
    "        \n",
    "            print(response_json['symbol'])\n",
    "\n",
    "            date.update(response_json)\n",
    "            \n",
    "            ## Append the combined dictionary to our desired list\n",
    "        \n",
    "            append_to.append(date)\n",
    "    \n",
    "            print('success')\n",
    "        except:\n",
    "            print(f\"Looks like you have been timed out, continue at {x} for {missing_dates[x]}\")\n",
    "            \n",
    "            \n",
    "            break\n",
    "            \n",
    "#     return append_to\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = get_data_missing_dates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb24472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add records using a session element\n",
    "\n",
    "for i in range(len(missing_data)):\n",
    "    \n",
    "    ## Since we have to add our own primary keys, findout max primary key\n",
    "    \n",
    "    last_primary_key = pd.read_sql_query(\"select max(id) from adding_bitcoin limit 10\", con=engine)['max'][0].item()\n",
    "\n",
    "    \n",
    "    next_primary_key = last_primary_key+1\n",
    "\n",
    "    \n",
    "    session.add(adding_bitcoin(id = next_primary_key, dt = missing_data[i]['date'],\n",
    "    name = 'bitcoin',\n",
    "    symbol = missing_data[i]['symbol'],\n",
    "    name_2 = missing_data[i]['name'],\n",
    "    localization = f\"{missing_data[i]['localization']}\",\n",
    "    image = f\"{missing_data[i]['image']}\",\n",
    "    market_data = f\"{missing_data[i]['market_data']}\",\n",
    "    community_data = f\"{missing_data[i]['community_data']}\",\n",
    "    developer_data = f\"{missing_data[i]['developer_data']}\",\n",
    "    public_interest_stats = f\"{missing_data[i]['public_interest_stats']}\"))\n",
    "\n",
    "    # Commit and close the session for the changes to be uploaded to the databse\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "print(\"SUCCESS!\")\n",
    "# session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f72bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('SELECT dt from bitcoin_four_years_data', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6411a3",
   "metadata": {},
   "source": [
    "## Example for reversing the order of a csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. import the csv file as a datafram and save it the the variable df\n",
    "\n",
    "#df = pd.read_csv('../static/data/bitcoin_four_years_data.csv').drop(columns='Unnamed: 0')\n",
    "\n",
    "## 2. Convert the dataframe to a list\n",
    "\n",
    "#bitcoin_four_years = df.values.tolist()\n",
    "\n",
    "## 3. Reverse the order of the list\n",
    "\n",
    "#bitcoin_four_years.reverse()\n",
    "\n",
    "## Export the dataframe out as a csv \n",
    "\n",
    "#pd.DataFrame(bitcoin_four_years).to_csv(\"../static/data/reversed_bitcoin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "047727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_database_updating_app_bitcoin_only(table_name):\n",
    "    \n",
    "    #################################################################\n",
    "    ## STEP 1: Get list of dates with missing data\n",
    "    #################################################################\n",
    "    \n",
    "    # Get today's date\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # Get the most recent date from data base using a query\n",
    "    \n",
    "    most_recent_entry_date = pd.read_sql_query(f\"select dt from {table_name} order by dt desc limit 1\", con=engine)['dt'][0]\n",
    "\n",
    "\n",
    "    ## Make list of dates between today and the most recent one, \n",
    "    ## First get the number of days\n",
    "    \n",
    "    num_days = (today - most_recent_entry_date).days -1\n",
    "\n",
    "\n",
    "    # Now make a list conprehension to provide the lists\n",
    "    \n",
    "    missing_dates_descending_order = [today - datetime.timedelta(days=x) for x in range(num_days)]\n",
    "    missing_dates_ascending_order = [today - datetime.timedelta(days=num_days) + datetime.timedelta(days=x)for x in range(num_days+1)]\n",
    "    \n",
    "    #################################################################\n",
    "    ## STEP 2: Make requests to api for missing date from the table\n",
    "    #################################################################\n",
    "    \n",
    "    \n",
    "    # Get the name of the token\n",
    "        \n",
    "    token = pd.read_sql_query(f\"select name from {table_name} order by id desc limit 1\", con=engine)['name'][0]\n",
    "    \n",
    "    ## Check to see if database is up to date\n",
    "    \n",
    "    if len(missing_dates_ascending_order) == 0:\n",
    "        print(\"Database up to date\")\n",
    "\n",
    "    for x in range(len(missing_dates_ascending_order)):\n",
    "        \n",
    "        session = Session(engine)\n",
    "        \n",
    "        dt = missing_dates_ascending_order[x]\n",
    "        print(\"now checking:\", missing_dates_ascending_order[x])\n",
    "        \n",
    "        url = f\"https://api.coingecko.com/api/v3/coins/{token}/history?date={missing_dates_ascending_order[x].strftime('%d-%m-20%y')}localization=False\"\n",
    "        \n",
    "        response_json = requests.get(url).json()\n",
    "        \n",
    "        #################################################################\n",
    "        ## STEP 3: COLLECT THE RESPONSE AND ADD IT TO DATABASE\n",
    "        #################################################################\n",
    "        \n",
    "        ## Since we have to add our own primary keys, find out max primary key number\n",
    "    \n",
    "        last_primary_key = pd.read_sql_query(f\"select max(id) from {table_name} limit 10\", con=engine)['max'][0].item()\n",
    "        next_primary_key = last_primary_key+1\n",
    "\n",
    "        ## Add our parameters to our session to update bitcoin_four_years_data\n",
    "        \n",
    "        id = next_primary_key \n",
    "        dt = dt\n",
    "        name = token\n",
    "        symbol = response_json['symbol']\n",
    "        name_2 = response_json['name']\n",
    "        localization = response_json['localization']\n",
    "        image = response_json['image']\n",
    "        market_data = response_json['market_data']\n",
    "        community_data = response_json['community_data']\n",
    "        developer_data = response_json['developer_data']\n",
    "        public_interest_stats = response_json['public_interest_stats']\n",
    "        \n",
    "        session.add(bitcoin_four_years_data(id = id, \n",
    "        dt = dt,\n",
    "        name = name,\n",
    "        symbol = symbol,\n",
    "        name_2 = name_2,\n",
    "        localization = f'{localization}',\n",
    "        image = f'{image}',\n",
    "        market_data = f'{market_data}',\n",
    "        community_data = f'{community_data}',\n",
    "        developer_data = f'{developer_data}',\n",
    "        public_interest_stats = f'{public_interest_stats}'))\n",
    "\n",
    "        # Commit and close the session for the changes to be uploaded to the databse\n",
    "\n",
    "       \n",
    "        \n",
    "        ##############################################################################\n",
    "        ## STEP 4: UNPACK COMMUNITY DATA AND ADD IT TO ITS TABLE\n",
    "        ##############################################################################\n",
    "        \n",
    "        facebook_likes = community_data['facebook_likes']\n",
    "        twitter_followers = community_data['twitter_followers']\n",
    "        reddit_average_posts_48h = community_data['reddit_average_posts_48h']\n",
    "        reddit_average_comments_48h = community_data['reddit_average_comments_48h']\n",
    "        reddit_subscribers = community_data['reddit_subscribers']\n",
    "        reddit_accounts_active_48h = community_data['reddit_accounts_active_48h']\n",
    "        \n",
    "        session.add(btc_community(\n",
    "        id = id,\n",
    "        dt = dt,\n",
    "        name = name,\n",
    "        facebook_likes = facebook_likes,\n",
    "        twitter_followers = twitter_followers,\n",
    "        reddit_average_posts_48h = reddit_average_posts_48h,\n",
    "        reddit_average_comments_48h = reddit_average_comments_48h,\n",
    "        reddit_subscribers = reddit_subscribers,\n",
    "        reddit_accounts_active_48h = reddit_accounts_active_48h\n",
    "        ))\n",
    "        \n",
    "        session.commit()\n",
    "        session.close()\n",
    "\n",
    "        \n",
    "    print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "750b9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f38460ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now checking: 2021-07-30\n",
      "now checking: 2021-07-31\n",
      "now checking: 2021-08-01\n",
      "now checking: 2021-08-02\n",
      "now checking: 2021-08-03\n",
      "now checking: 2021-08-04\n",
      "now checking: 2021-08-05\n",
      "now checking: 2021-08-06\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "master_database_updating_app_bitcoin_only('bitcoin_four_years_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f165c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27ee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcef33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc6bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15fb18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1888f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd51a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
